# LLM-TAMIS

## Overview
LLM-TAMIS is a large language model-based text-augmented medical image segmentation method. It integrates both visual and textual data. By leveraging large language models (LLMs) and multimodal data, our method enhances segmentation accuracy by incorporating relevant contextual information from clinical reports and annotations.

Additionally, we introduce a new Spatial Channel Driven Module (SCDM), which refines feature extraction by focusing on important spatial regions and relevant feature channels. This results in more accurate and robust segmentation. We evaluate our method on two publicly available medical image datasets, demonstrating that our approach outperforms state-of-the-art methods in segmentation accuracy, achieving superior results across multiple evaluation metrics.

